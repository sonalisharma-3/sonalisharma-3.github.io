---
layout: single
title: "Research Overview"
permalink: /research/
author_profile: true
classes: wide
---
## Recent Work

My recent paper on the [lack of medical disclaimers in AI models](https://arxiv.org/abs/2507.08030) was featured in:

- **MIT Technology Review**: ["AI companies have stopped warning you that their chatbots aren't doctors"](https://www.technologyreview.com/2025/07/21/1120522/ai-companies-have-stopped-warning-you-that-their-chatbots-arent-doctors/)

- **Computerworld**: ["AI chatbots ditch medical disclaimers, putting users at risk, study warns"](https://www.computerworld.com/article/4026778/ai-chatbots-ditch-medical-disclaimers-putting-users-at-risk-study-warns.html)

## Other Projects

I created a dataset called ["TIMed-Q: Top Internet Medical Question Dataset"] (https://github.com/sonalisharma-3/TIMed-Q)
- TIMed-Q is a curated dataset of 500 patient-phrased medical questions sourced from real-world internet searches. 
- It is designed to support research in Large Language Models (LLMs), clinical reasoning, and medical safety evaluation by capturing the authentic language and concerns of patients seeking medical information online.

## Publications

-[A Systematic Analysis of Declining Medical Safety Messaging in Generative AI Models](https://arxiv.org/abs/2507.08030)

*[contact me](mailto:sonali3@stanford.edu).*
