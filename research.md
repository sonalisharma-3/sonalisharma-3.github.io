---
layout: single
title: "Research"
permalink: /research/
author_profile: true
classes: wide
---

# Research Overview

My research sits at the critical intersection of **AI safety**, **healthcare**, and **policy**. As AI systems become more prevalent in medical settings, ensuring they are safe, reliable, and beneficial is paramount. I focus on developing frameworks and methodologies that enable responsible AI deployment in healthcare, with particular expertise in radiology applications.

---

## Primary Research Areas

### üè• AI Safety in Healthcare
Developing comprehensive safety frameworks for AI systems in clinical environments. This includes studying failure modes, establishing safety benchmarks, and creating protocols for safe AI deployment in high-stakes medical scenarios.

**Key Focus Areas:**
- Safety assessment methodologies for medical AI systems
- Risk mitigation strategies for AI-assisted diagnosis
- Human-AI collaboration frameworks in clinical settings
- Patient safety protocols for AI-enhanced healthcare

### üìä Medical Imaging & Radiology AI
Advancing the safe and effective use of AI in medical imaging, particularly in radiology workflows. This research addresses both technical challenges and practical implementation concerns.

**Current Projects:**
- Evaluating AI diagnostic accuracy across diverse patient populations
- Developing explainable AI methods for radiological diagnosis
- Studying the impact of AI assistance on radiologist decision-making
- Creating validation frameworks for medical imaging AI

### üèõÔ∏è AI Governance & Policy
Examining the regulatory, ethical, and policy implications of AI in healthcare. This work informs evidence-based policy recommendations for responsible AI governance.

**Research Questions:**
- How should medical AI systems be regulated to ensure patient safety?
- What disclosure requirements should exist for AI-assisted medical advice?
- How can we balance innovation with patient protection?
- What governance structures best support responsible AI development?

---

## Recent Research Highlights

### Medical Disclaimer Study
*Featured in MIT Technology Review & Computerworld*

Conducted comprehensive analysis of how AI companies are handling medical disclaimers and warnings. This research revealed concerning trends in the removal of safety warnings from AI health tools, highlighting potential risks to users seeking medical information.

**Key Findings:**
- Systematic reduction in medical disclaimers across major AI platforms
- Potential patient safety implications of unrestricted AI medical advice
- Need for regulatory frameworks governing AI health communication

**Impact:** This research has informed policy discussions and raised awareness about the need for responsible AI deployment in health contexts.

---

## Research Philosophy

My approach to AI safety research is grounded in several core principles:

**Human-Centered Design**: AI systems must be designed with human needs, limitations, and safety as the primary considerations.

**Empirical Rigor**: Research must be based on solid empirical evidence and real-world testing, not just theoretical frameworks.

**Interdisciplinary Collaboration**: Effective AI safety research requires collaboration across computer science, medicine, policy, and ethics.

**Practical Impact**: Research should translate into actionable guidelines and tools that can be implemented by practitioners and policymakers.

---

*For detailed information about specific projects, collaborations, or research opportunities, please [contact me](mailto:sonali3@stanford.edu).*
